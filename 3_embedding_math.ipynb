{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_embedding_math.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGb+fJYi2cUqu++qTSmVQu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/NLP_course_at_ISB/blob/main/3_embedding_math.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuL-iyICj6oB"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running on local machine?\n",
        "# in case of errors with conda, try this:\n",
        "# conda install -c conda-forge spacy"
      ],
      "metadata": {
        "id": "8o2E2Wq6kZUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the default model in Spacy\n",
        "# nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "10LA2cQTkbRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the large language model for English\n",
        "# might take some time to download\n",
        "\n",
        "# uncomment the next line if default English model data cannot be located\n",
        "# !python -m spacy download en\n",
        "\n",
        "# uncomment the next line if the large model for English cannot be located\n",
        "# !python -m spacy download en_core_web_lg\n",
        "\n",
        "!python -m spacy link en_core_web_lg en --force\n",
        "# use the large model as the default model for English textual data\n",
        "\n",
        "nlp = spacy.load(\"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BzDrjoCkc5W",
        "outputId": "e4b602d3-0712-4955-cd33-31ca80e1e375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_lg -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(vec_A, vec_B):\n",
        "    return np.dot(np.asarray(vec_A), np.asarray(vec_B)) / (np.linalg.norm(np.asarray(vec_A)) * np.linalg.norm(np.asarray(vec_B)))"
      ],
      "metadata": {
        "id": "UtM6Bz2xkefs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Will try out various 'Similarity' Tasks for Word Embeddings"
      ],
      "metadata": {
        "id": "QY6cZSaokknZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gender\n",
        "\n",
        "tokens = nlp(\"king man woman queen\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'king'):\n",
        "        vec_king = token.vector\n",
        "    if(token.text == 'man'):\n",
        "        vec_man = token.vector\n",
        "    if(token.text == 'woman'):\n",
        "        vec_woman = token.vector\n",
        "    if(token.text == 'queen'):\n",
        "        vec_queen = token.vector\n",
        "\n",
        "new_vec = vec_king - vec_man + vec_woman\n",
        "print(cosine_similarity(new_vec, vec_queen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLcUuQdXkh-4",
        "outputId": "19bcabd5-e217-4a65-a2cf-8ee54f708be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.78808445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Capital Cities\n",
        "\n",
        "tokens = nlp(\"paris france tokyo japan\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'paris'):\n",
        "        vec_paris = token.vector\n",
        "    if(token.text == 'france'):\n",
        "        vec_france = token.vector\n",
        "    if(token.text == 'tokyo'):\n",
        "        vec_tokyo = token.vector\n",
        "    if(token.text == 'japan'):\n",
        "        vec_japan = token.vector\n",
        "        \n",
        "new_vec = vec_paris - vec_france + vec_japan\n",
        "print(cosine_similarity(new_vec, vec_tokyo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30QLkYYqknuJ",
        "outputId": "6035ead4-4daa-4d2e-91d6-69eff46bfa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.79177994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pluralization\n",
        "\n",
        "tokens = nlp(\"mouse mice chair chairs\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'mouse'):\n",
        "        vec_mouse = token.vector\n",
        "    if(token.text == 'mice'):\n",
        "        vec_mice = token.vector\n",
        "    if(token.text == 'chair'):\n",
        "        vec_chair = token.vector\n",
        "    if(token.text == 'chairs'):\n",
        "        vec_chairs = token.vector\n",
        "        \n",
        "new_vec = vec_mice - vec_mouse + vec_chair\n",
        "print(cosine_similarity(new_vec, vec_chairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LqS-Tj6kpsV",
        "outputId": "fed724d9-9cb4-4fd8-a5c1-fdf8f39ff374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6925059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Superlative Degree\n",
        "\n",
        "tokens = nlp(\"good best cold colder\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'cold'):\n",
        "        vec_cold = token.vector\n",
        "    if(token.text == 'colder'):\n",
        "        vec_colder = token.vector\n",
        "    if(token.text == 'best'):\n",
        "        vec_best = token.vector\n",
        "    if(token.text == 'good'):\n",
        "        vec_good = token.vector\n",
        "        \n",
        "new_vec = vec_colder - vec_cold + vec_good\n",
        "print(cosine_similarity(new_vec, vec_best))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf6I4ewBkq8G",
        "outputId": "14597d10-7c12-456e-e76c-de6e372cd38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4129227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Present Participle Forms\n",
        "\n",
        "tokens = nlp(\"think thinking read reading\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'think'):\n",
        "        vec_think = token.vector\n",
        "    if(token.text == 'thinking'):\n",
        "        vec_thinking = token.vector\n",
        "    if(token.text == 'read'):\n",
        "        vec_read = token.vector\n",
        "    if(token.text == 'reading'):\n",
        "        vec_reading = token.vector\n",
        "        \n",
        "new_vec = vec_thinking - vec_think + vec_read\n",
        "print(cosine_similarity(new_vec, vec_reading))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHhB2pL6ksnt",
        "outputId": "93d405c5-880d-4750-984b-24d78502316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.78735167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Opposites\n",
        "\n",
        "tokens = nlp(\"possible impossible ethical unethical\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'possible'):\n",
        "        vec_possible = token.vector\n",
        "    if(token.text == 'impossible'):\n",
        "        vec_impossible = token.vector\n",
        "    if(token.text == 'ethical'):\n",
        "        vec_ethical = token.vector\n",
        "    if(token.text == 'unethical'):\n",
        "        vec_unethical = token.vector\n",
        "        \n",
        "new_vec = vec_impossible - vec_possible + vec_ethical\n",
        "print(cosine_similarity(new_vec, vec_unethical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-ghKAnWkuJ2",
        "outputId": "38000391-05e4-4d7c-9ff8-305470e98ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.54883933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $> Differenece\\ between\\ the\\ small\\ and\\ large\\ models\\ for \\ English. $\n",
        "##### - $ Check\\ out\\ the\\ medium-sized\\ model. $\n",
        "#### $> Try\\ out\\ other\\ operations\\ using\\ the\\ vectors.$\n",
        "##### - $ Does\\ Vector\\ Difference\\ really\\ capture\\ co-occurence\\ probability?$\n",
        "##### - $ Do\\ distance\\ based\\ metrics\\ add\\ anything\\ to\\ the\\ picture? $\n",
        "##### - $ Can\\ you\\ define\\ your\\ own\\ weighted\\ similarity\\ metric?\\ What\\ motivates\\ such\\ definitions?$\n"
      ],
      "metadata": {
        "id": "mCXK9mfCkyT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ^_^ Thank You"
      ],
      "metadata": {
        "id": "XscARkpVky9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}